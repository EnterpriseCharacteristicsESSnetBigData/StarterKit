{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WPC-Social-Media-Presence STARTER KIT\n",
    "\n",
    "This part of the WPC Starter Kit covers how to find social media links on enterprise websites.\n",
    "\n",
    "Input: either a list of URLs or scraped data in a MongoDB database as returned by [DomainScraper](https://github.com/EnterpriseCharacteristicsESSnetBigData/StarterKit/tree/master/URLScraper)\n",
    "\n",
    "Output: A csv file containing domain names and found social media links\n",
    "\n",
    "\n",
    "## 0. Prerequisites - how to set up the Python environment\n",
    "\n",
    "\n",
    "Python 3 is used for this library. We recommend to install Python with the Anaconda distribution, which can be obtained [here](https://www.anaconda.com/distribution/).\n",
    "\n",
    "\n",
    "Remember to use only Python version 3 - on Python 2 the library will not work.\n",
    "\n",
    "\n",
    "An installation of the following libaries is needed:\n",
    "<ul>\n",
    "    <li>bs4</li> \n",
    "    <li>requests (part of Anaconda)</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "## 1. Importing the library\n",
    "\n",
    "The file SocialMediaCollector.py is located in the src folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "\n",
    "import SocialMediaPresenceCollector as smpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initiating the class SocialMediaPresence\n",
    "The class SocialMediaPresence has one parameter: a dictionary of social media platforms with lists of their domain URLs as values. By default, it will collect social media links to Facebook, Twitter, Youtube, LinkedIn, Instagram, Xing and Pinterest. We will use this default in the starter kit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp=smpc.SocialMediaPresence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the default dictionary with social media domains. Different social media platforms can be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Facebook': ['facebook.com'],\n",
       " 'Twitter': ['twitter.com'],\n",
       " 'Youtube': ['youtu.be', 'youtube.com'],\n",
       " 'LinkedIn': ['linkedin.com'],\n",
       " 'Instagram': ['instagram.com'],\n",
       " 'Xing': ['xing.com'],\n",
       " 'Pinterest': ['pinterest.com']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp.social_media_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Option 1: Providing a list of URLs as input\n",
    "\n",
    "\n",
    "### 3.1 Reading the URL data\n",
    "The data source containing the URLs can be an iterable like a list, or a data frame column containing enterprise URLs. For this starer kit, we use an input file that is line-separated and looks like this:\n",
    "\n",
    "maslankowski.pl<br/>\n",
    "http://stat.gov.pl<br/>\n",
    "www.ug.edu.pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'url.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the input file\n",
    "url_data = open(data_file,\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scraping URLs and finding Social Media Links\n",
    "Before scraping URLs and finding social media links, a FileAccess object has to be instantiated that will save the found links in both a json and csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the class FileAccess\n",
    "fa = smpc.FileAccess()\n",
    "# Results will be stored in a list\n",
    "jsonList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop through the URLs from our input file and first scrape these URLs with the requests library. Then, we use the SocialMediaLinks method of SocialMediaPresence to identify and safe social media links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Website currently being scraped: stat.gov.pl\n",
      "\n",
      "The length of the scrapped content: 90079 characters\n",
      "Number of links on website: 255\n",
      "https://www.youtube.com/channel/UC0wiQMElFgYszpAoYgTnXtg/featured\n",
      "https://www.facebook.com/GlownyUrzadStatystyczny/\n",
      "http://twitter.com/GUS_STAT\n",
      "https://www.linkedin.com/company/532930\n",
      "https://www.instagram.com/gus_stat/\n",
      "https://twitter.com/GUS_STAT/lists/gus-i-urz-dy-statystyczne?ref_src=twsrc%5Etfw\n",
      "Total number of unique social media links found: 6\n",
      "\n",
      "Website currently being scraped: http://ug.edu.pl\n",
      "\n",
      "The length of the scrapped content: 60769 characters\n",
      "Number of links on website: 137\n",
      "https://www.facebook.com/UniwersytetGdanski\n",
      "https://twitter.com/uniwersytet_gd\n",
      "https://www.instagram.com/uniwersytet_gdanski/\n",
      "https://www.youtube.com/channel/UCOrHv73IWNIetJveGjV_zLA\n",
      "https://pl.linkedin.com/school/uniwersytet-gda%C5%84ski/\n",
      "Total number of unique social media links found: 5\n",
      "\n",
      "Website currently being scraped: maslankowski.pl\n",
      "\n",
      "The length of the scrapped content: 4869 characters\n",
      "Number of links on website: 14\n",
      "https://twitter.com/jmaslankowski\n",
      "https://twitter.com/jmaslankowski?ref_src=twsrc%5Etfw\n",
      "Total number of unique social media links found: 2\n"
     ]
    }
   ],
   "source": [
    "for url in url_data:\n",
    "    print(\"\\nWebsite currently being scraped:\", url)\n",
    "    jsonList.append(smp.searchSocialMediaLinks(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.jsonListWrite(jsonList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.3 Output files\n",
    "\n",
    "The output of the application are two files:\n",
    "<b>wpc_social.csv</b>\n",
    "and\n",
    "<b>wpc_social_YYYYMMDDHHMMSSnnnnnnn.json</b>\n",
    "<br/><br/>\n",
    "The file <b>wpc_social.csv</b> is updated with its content. \n",
    "<br/><br/>\n",
    "The json file is created every time of the application running.\n",
    "<br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Option 2: Using scraped data obtained by DomainScraper as input\n",
    "In case you want to scrape enterprise websites once and then derive different characteristics from it, it makes sense to first scrape and save the data with DomainScraper. Your MongoDB database can serve as data source for the SocialMediaPresenceCollector.\n",
    "\n",
    "This part only works if you already created a MongoDB database with web scraped enterprise websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create a connection to the MongoDB server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "host='localhost'\n",
    "port=27017\n",
    "# define the client connection\n",
    "# host - default localhost\n",
    "# port - default 27017\n",
    "client=MongoClient('mongodb://'+str(host)+\":\"+str(port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname='URLScraping' # Change to the name of your MongoDB database with scraped data\n",
    "try:\n",
    "    database=client[dbname]\n",
    "except:\n",
    "    print('Error connecting the database', sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName = database.websites # Change to your collection name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Use scraped data to find social media links\n",
    "Results are saved in the file 'wp2_social.csv' within your working directory.\n",
    "\n",
    "Optional: You can specify a timespan in searchSocialMediaLinksNoSQL so that only data that was scraped within that time will be used by the SocialMediaPresenceCollector. \n",
    "\n",
    "Default: Starting date: '2020-01-01'; End date: today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat.gov.pl 2020-09-16 16:53:09.260800\n",
      "The length of the scrapped content: 89746 characters\n",
      "Number of links on website: 255\n",
      "https://www.youtube.com/channel/UC0wiQMElFgYszpAoYgTnXtg/featured\n",
      "https://www.facebook.com/GlownyUrzadStatystyczny/\n",
      "http://twitter.com/GUS_STAT\n",
      "https://www.linkedin.com/company/532930\n",
      "https://www.instagram.com/gus_stat/\n",
      "https://twitter.com/GUS_STAT/lists/gus-i-urz-dy-statystyczne?ref_src=twsrc%5Etfw\n",
      "Total number of unique social media links found: 6\n",
      "{'URL': 'stat.gov.pl', 'Facebook': ['https://www.facebook.com/GlownyUrzadStatystyczny/'], 'Twitter': ['http://twitter.com/GUS_STAT', 'https://twitter.com/GUS_STAT/lists/gus-i-urz-dy-statystyczne?ref_src=twsrc%5Etfw'], 'Youtube': ['https://www.youtube.com/channel/UC0wiQMElFgYszpAoYgTnXtg/featured'], 'LinkedIn': ['https://www.linkedin.com/company/532930'], 'Instagram': ['https://www.instagram.com/gus_stat/'], 'Xing': [], 'Pinterest': []}\n",
      "destatis.de 2020-09-16 16:53:09.695800\n",
      "The length of the scrapped content: 83069 characters\n",
      "Number of links on website: 113\n",
      "https://twitter.com/destatis/status/1306212809857007617\n",
      "https://twitter.com/intent/like?tweet_id=1306212809857007617\n",
      "https://twitter.com/intent/retweet?tweet_id=1306212809857007617\n",
      "https://twitter.com/destatis\n",
      "https://www.youtube.com/user/destatis\n",
      "https://www.xing.com/jobs/statistisches-bundesamt\n",
      "Total number of unique social media links found: 6\n",
      "{'URL': 'destatis.de', 'Facebook': [], 'Twitter': ['https://twitter.com/destatis', 'https://twitter.com/destatis/status/1306212809857007617', 'https://twitter.com/intent/retweet?tweet_id=1306212809857007617', 'https://twitter.com/intent/like?tweet_id=1306212809857007617'], 'Youtube': ['https://www.youtube.com/user/destatis'], 'LinkedIn': [], 'Instagram': [], 'Xing': ['https://www.xing.com/jobs/statistisches-bundesamt'], 'Pinterest': []}\n",
      "nsi.bg 2020-09-16 16:53:11.020800\n",
      "The length of the scrapped content: 90880 characters\n",
      "Number of links on website: 283\n",
      "https://www.facebook.com/nsibg\n",
      "http://www.youtube.com/user/bgnsi\n",
      "Total number of unique social media links found: 2\n",
      "{'URL': 'nsi.bg', 'Facebook': ['https://www.facebook.com/nsibg'], 'Twitter': [], 'Youtube': ['http://www.youtube.com/user/bgnsi'], 'LinkedIn': [], 'Instagram': [], 'Xing': [], 'Pinterest': []}\n"
     ]
    }
   ],
   "source": [
    "smp.searchSocialMediaLinksNoSQL(collectionName, dateFrom='2020-01-01', dateUntil=datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
